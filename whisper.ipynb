{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cda3d337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deniska/varya/project_transcribe/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tempfile\n",
    "import torchaudio\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2141396e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deniska/varya/project_transcribe/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "asr_pipeline = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"openai/whisper-large-v3\",\n",
    "    chunk_length_s=20,                 \n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch.float16,         \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a63b91ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio_file(audio_bytes: bytes, original_filename: str, return_timestamps: bool = False):\n",
    "    ext = os.path.splitext(original_filename)[1].lower()\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix=ext, delete=True) as temp_audio:\n",
    "        temp_audio.write(audio_bytes)\n",
    "        temp_audio.flush()\n",
    "\n",
    "        waveform, sample_rate = torchaudio.load(temp_audio.name)\n",
    "\n",
    "        if sample_rate != 16000:\n",
    "            waveform = torchaudio.functional.resample(waveform, sample_rate, 16000)\n",
    "\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "        audio_input = waveform.squeeze().numpy()\n",
    "\n",
    "        result = asr_pipeline(\n",
    "            audio_input,\n",
    "            batch_size=8,\n",
    "            return_timestamps=return_timestamps,\n",
    "            generate_kwargs={\"language\": \"ru\"} \n",
    "        )\n",
    "\n",
    "        return result[\"chunks\"] if return_timestamps else result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f14b4098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "def download_audio_from_youtube(url: str) -> tuple[bytes, str]:\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        output_path = os.path.join(tmpdir, \"%(title)s.%(ext)s\")\n",
    "        ydl_opts = {\n",
    "            \"format\": \"bestaudio/best\",\n",
    "            \"outtmpl\": output_path,\n",
    "            \"noplaylist\": True,\n",
    "            \"quiet\": True,\n",
    "            \"postprocessors\": [{\n",
    "                \"key\": \"FFmpegExtractAudio\",\n",
    "                \"preferredcodec\": \"mp3\",\n",
    "                \"preferredquality\": \"192\",\n",
    "            }],\n",
    "        }\n",
    "\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            info_dict = ydl.extract_info(url, download=True)\n",
    "            filename = ydl.prepare_filename(info_dict).rsplit(\".\", 1)[0] + \".mp3\"\n",
    "\n",
    "        with open(filename, \"rb\") as f:\n",
    "            audio_bytes = f.read()\n",
    "\n",
    "        return audio_bytes, os.path.basename(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8463c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # with open(filename, \"rb\") as f:\n",
    "    #     audio = f.read()\n",
    "    youtube_url = input(\"ÑÑÑ‹Ð»ÐºÐ° Ð½Ð° ÑŽÑ‚ \").strip()\n",
    "\n",
    "    print(\"\\nÑÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ðµ...\")\n",
    "    audio, filename = download_audio_from_youtube(youtube_url)\n",
    "    \n",
    "    print(\"\\nÐ¢ÐžÐ›Ð¬ÐšÐž Ð¢Ð•ÐšÐ¡Ð¢-------\")\n",
    "    text = transcribe_audio_file(audio, filename, return_timestamps=False)\n",
    "    print(text)\n",
    "\n",
    "    print(\"\\nÐ¢Ð•ÐšÐ¡Ð¢ Ð¡ Ð¢ÐÐ™ÐœÐšÐžÐ”ÐÐœÐ˜---------\")\n",
    "    chunks = transcribe_audio_file(audio, filename, return_timestamps=True)\n",
    "    for chunk in chunks:\n",
    "        print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "304f6622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Ð¡ÐºÐ°Ñ‡Ð¸Ð²Ð°ÐµÐ¼ https://youtu.be/ozmAG58n12k?si=DR7nurcTa14Zy5WK Ð² MP3...\n",
      "[youtube] Extracting URL: https://youtu.be/ozmAG58n12k?si=DR7nurcTa14Zy5WK\n",
      "[youtube] ozmAG58n12k: Downloading webpage\n",
      "[youtube] ozmAG58n12k: Downloading tv client config\n",
      "[youtube] ozmAG58n12k: Downloading tv player API JSON\n",
      "[youtube] ozmAG58n12k: Downloading ios player API JSON\n",
      "[youtube] ozmAG58n12k: Downloading player 461f4c95-main\n",
      "[youtube] ozmAG58n12k: Downloading m3u8 information\n",
      "[info] ozmAG58n12k: Downloading 1 format(s): 251\n",
      "[download] Destination: /home/deniska/Downloads/Ð›ÑƒÑ‡ÑˆÐ¸Ð¹ Ð´Ð¸Ð°Ð»Ð¾Ð³ Ð·Ð° Ð²ÑÑŽ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ ÐºÐ¸Ð½ÐµÐ¼Ð°Ñ‚Ð¾Ð³Ñ€Ð°Ñ„Ð°.webm\n",
      "[download] 100% of  436.84KiB in 00:00:00 at 731.85KiB/s \n",
      "[ExtractAudio] Destination: /home/deniska/Downloads/Ð›ÑƒÑ‡ÑˆÐ¸Ð¹ Ð´Ð¸Ð°Ð»Ð¾Ð³ Ð·Ð° Ð²ÑÑŽ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ ÐºÐ¸Ð½ÐµÐ¼Ð°Ñ‚Ð¾Ð³Ñ€Ð°Ñ„Ð°.mp3\n",
      "Deleting original file /home/deniska/Downloads/Ð›ÑƒÑ‡ÑˆÐ¸Ð¹ Ð´Ð¸Ð°Ð»Ð¾Ð³ Ð·Ð° Ð²ÑÑŽ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ ÐºÐ¸Ð½ÐµÐ¼Ð°Ñ‚Ð¾Ð³Ñ€Ð°Ñ„Ð°.webm (pass -k to keep)\n",
      "âœ… Ð¡ÐºÐ°Ñ‡Ð°Ð½Ð¾ Ð²: /home/deniska/Downloads\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yt_dlp\n",
    "from pathlib import Path\n",
    "\n",
    "def download_youtube_audio(url: str):\n",
    "    downloads_path = str(Path.home() / \"Downloads\")\n",
    "\n",
    "    ydl_opts = {\n",
    "        \"format\": \"bestaudio/best\",\n",
    "        \"outtmpl\": os.path.join(downloads_path, \"%(title)s.%(ext)s\"),\n",
    "        \"noplaylist\": True,\n",
    "        \"quiet\": False,\n",
    "        \"postprocessors\": [\n",
    "            {\n",
    "                \"key\": \"FFmpegExtractAudio\",\n",
    "                \"preferredcodec\": \"mp3\",\n",
    "                \"preferredquality\": \"192\",\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        print(f\"ðŸ“¥ Ð¡ÐºÐ°Ñ‡Ð¸Ð²Ð°ÐµÐ¼ {url} Ð² MP3...\")\n",
    "        ydl.download([url])\n",
    "        print(f\"âœ… Ð¡ÐºÐ°Ñ‡Ð°Ð½Ð¾ Ð²: {downloads_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    youtube_url = input(\"ÑÑÑ‹Ð»ÐºÐ° Ð½Ð° ÑŽÑ‚ÑƒÐ±: \").strip()\n",
    "    download_youtube_audio(youtube_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb0e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "474eef72",
   "metadata": {},
   "source": [
    "```bash\n",
    "pip install git+https://github.com/huggingface/speechbox\n",
    "pip install pyannote.audio torch torchaudio\n",
    "```\n",
    "\n",
    "```python\n",
    "from speechbox import ASRDiarizationPipeline\n",
    "from transformers import pipeline as hf_pipeline\n",
    "from pyannote.audio import Pipeline as DiarizationPipeline\n",
    "import tempfile\n",
    "import torchaudio\n",
    "import torch\n",
    "import os\n",
    "import gc\n",
    "from config import HF_TOKEN  \n",
    "\n",
    "\n",
    "asr_pipeline = hf_pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"openai/whisper-large-v3\",\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "\n",
    "diarization_pipeline = DiarizationPipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.0\",\n",
    "    use_auth_token=HF_TOKEN,\n",
    ")\n",
    "\n",
    "combined_pipeline = ASRDiarizationPipeline(\n",
    "    asr_pipeline=asr_pipeline,\n",
    "    diarization_pipeline=diarization_pipeline,\n",
    ")\n",
    "\n",
    "def transcribe_audio_file(audio_bytes: bytes, original_filename: str):\n",
    "    ext = os.path.splitext(original_filename)[1].lower()\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix=ext, delete=True) as temp_audio:\n",
    "        temp_audio.write(audio_bytes)\n",
    "        temp_audio.flush()\n",
    "\n",
    "        waveform, sample_rate = torchaudio.load(temp_audio.name)\n",
    "\n",
    "        if sample_rate != 16000:\n",
    "            waveform = torchaudio.functional.resample(waveform, sample_rate, 16000)\n",
    "\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "        input_tensor = waveform.float()  # (1, seq_len)\n",
    "        if len(input_tensor.shape) == 1:\n",
    "            input_tensor = input_tensor.unsqueeze(0)\n",
    "\n",
    "        outputs = combined_pipeline({\n",
    "            \"waveform\": input_tensor,\n",
    "            \"sample_rate\": sample_rate\n",
    "        })\n",
    "\n",
    "\n",
    "        def tuple_to_string(t, ndigits=1):\n",
    "            return f\"({round(t[0], ndigits)}, {round(t[1], ndigits)})\"\n",
    "\n",
    "        def format_as_dialogue(segments):\n",
    "            speaker_map = {}\n",
    "            dialogue_lines = []\n",
    "            speaker_counter = 1\n",
    "\n",
    "            for seg in segments:\n",
    "                speaker = seg[\"speaker\"]\n",
    "                if speaker not in speaker_map:\n",
    "                    speaker_map[speaker] = f\"Ð¡Ð¿Ð¸ÐºÐµÑ€ {speaker_counter}\"\n",
    "                    speaker_counter += 1\n",
    "                label = speaker_map[speaker]\n",
    "                dialogue_lines.append(f\"{label}: {seg['text'].strip()}\")\n",
    "\n",
    "            return \"\\n\".join(dialogue_lines)\n",
    "\n",
    "        dialogue_text = format_as_dialogue(outputs)\n",
    "\n",
    "        full_text = \" \".join([s[\"text\"].strip() for s in outputs])\n",
    "        speaker_chunks = outputs  \n",
    "\n",
    "        return {\n",
    "            \"full_text\": full_text,\n",
    "            \"speaker_chunks\": speaker_chunks,\n",
    "            \"dialogue_text\": dialogue_text\n",
    "        }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a923ad",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
