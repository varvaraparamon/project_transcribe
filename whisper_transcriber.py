import torch
import tempfile
import torchaudio
from transformers import pipeline
from datasets import load_dataset
import os
import yt_dlp
import gc

device = "cuda" if torch.cuda.is_available() else "cpu"

asr_pipeline = pipeline(
    "automatic-speech-recognition",
    model="openai/whisper-large-v3",
    chunk_length_s=20,                 
    return_timestamps=True,
    torch_dtype=torch.float16,         
    device=device,
)

def transcribe_audio_file(audio_bytes: bytes, original_filename: str, return_timestamps: bool = False):
    """
    –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ—Ñ–∞–π–ª, –≤–æ–∑–≤—Ä–∞—â–∞—è —Ç–µ–∫—Å—Ç –∏–ª–∏ —á–∞–Ω–∫–∏ —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏.

    :param audio_bytes: —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ –≤ –±–∞–π—Ç–∞—Ö
    :param original_filename: –∏–º—è —Ñ–∞–π–ª–∞ (–Ω—É–∂–Ω–æ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è)
    :param return_timestamps: –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ª–∏ —Ç–∞–π–º–∫–æ–¥—ã
    :return: —Å—Ç—Ä–æ–∫–∞ —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ —Å–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤ —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏
    """
    ext = os.path.splitext(original_filename)[1].lower()

    with tempfile.NamedTemporaryFile(suffix=ext, delete=True) as temp_audio:
        torch.cuda.empty_cache()
        gc.collect()
        temp_audio.write(audio_bytes)
        temp_audio.flush()

        waveform, sample_rate = torchaudio.load(temp_audio.name)

        if sample_rate != 16000:
            waveform = torchaudio.functional.resample(waveform, sample_rate, 16000)

        if waveform.shape[0] > 1:
            waveform = waveform.mean(dim=0, keepdim=True)

        audio_input = waveform.squeeze().numpy()

        result = asr_pipeline(
            audio_input,
            batch_size=8,
            return_timestamps=return_timestamps,
            generate_kwargs={"language": "ru"} 
        )

        return result["chunks"] if return_timestamps else result["text"]
    

def download_audio_from_youtube(url: str) -> tuple[bytes, str]:
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ —Å YouTube –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ –∫–∞–∫ –±–∞–π—Ç—ã –∏ –∏–º—è —Ñ–∞–π–ª–∞.
    """
    with tempfile.TemporaryDirectory() as tmpdir:
        output_path = os.path.join(tmpdir, "%(title)s.%(ext)s")
        ydl_opts = {
            "format": "bestaudio/best",
            "outtmpl": output_path,
            "noplaylist": True,
            "quiet": True,
            "postprocessors": [{
                "key": "FFmpegExtractAudio",
                "preferredcodec": "mp3",
                "preferredquality": "192",
            }],
        }

        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info_dict = ydl.extract_info(url, download=True)
            filename = ydl.prepare_filename(info_dict).rsplit(".", 1)[0] + ".mp3"

        with open(filename, "rb") as f:
            audio_bytes = f.read()

        return audio_bytes, os.path.basename(filename)
    

if __name__ == "__main__":
    torch.cuda.empty_cache()
    gc.collect()
    filename = ""
    # with open(filename, "rb") as f:
    #     audio = f.read()
    youtube_url = input("–í—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ YouTube: ").strip()

    print("\nüì• –°–∫–∞—á–∏–≤–∞–µ–º –∞—É–¥–∏–æ...")
    audio, filename = download_audio_from_youtube(youtube_url)
    
    print("\n=== –¢–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç ===")
    text = transcribe_audio_file(audio, filename, return_timestamps=False)
    print(text)

    print("\n=== –° —Ç–∞–π–º–∫–æ–¥–∞–º–∏ ===")
    chunks = transcribe_audio_file(audio, filename, return_timestamps=True)
    for chunk in chunks:
        print(chunk)
    torch.cuda.empty_cache()
    gc.collect()