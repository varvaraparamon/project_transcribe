from huggingface_hub import login
from dotenv import load_dotenv
import os

load_dotenv()
HUGGINGFACE_TOKEN = os.getenv("HUGGINGFACE_TOKEN")
login(HUGGINGFACE_TOKEN)

from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace

prompt = """
Вход:
транскрипт отдельной лекции.

Выход:
Раздел 1 — структурированный анализ каждой лекции.
Раздел 2 — оригинальные вопросы для дискуссий, опираясь на содержание лекций, но не повторяющие очевидное.

Раздел 1. Анализ лекций
- Название лекции  название файла без расширения.
- Краткое содержание — 3–5 предложений, отражающих суть лекции. Только факты и формулировки, которые реально прозвучали.
- Выводы лекции — 3–5 ключевых мыслей спикера, без добавления своих интерпретаций.
- Тезисы лекции — 3–5 коротких пунктов (одно-два предложения каждый), отражающих конкретные утверждения, озвученные на лекции.

Требования:
- Не добавлять собственных идей или прогнозов.
- Формулировки должны быть основаны на реальных данных из лекции.
- Убирать повторы.

Формат ответа

## [Номер лекции]. [Название лекции]

Краткое содержание  
[Текст]

Выводы лекции  
- [Вывод 1]  
- [Вывод 2]  
- [Вывод 3]  

Тезисы лекции  
- [Тезис 1]  
- [Тезис 2]  
- [Тезис 3]  

Раздел 2. Вопросы для дискуссий
Задача: На основе всех тезисов из Часть 1 составить 5–7 вопросов, которые:
- Неочевидны — отсутствуют в явном виде в лекции, но логично вытекают из сказанного.
- Междисциплинарны — соединяют тему лекции с трендами в технологиях, социологии, экономике и др.
- Провокационны — мягко бросают вызов устоявшимся подходам.
- Практико-ориентированы — содержат примеры или отсылки к реальным кейсам.

Требования:
- Каждый вопрос сопровождается обоснованием и целевой аудиторией.
- Обоснование — почему этот вопрос актуален сейчас (2023–2024).
- Целевая аудитория — кто на мероприятии мог бы ответить или обсудить (например, участники секции по [тема]).
- Не повторять формулировки из лекций, но основываться на их сути.

Формат ответа (Раздел 2):

### [Вопрос]
Обоснование: [пояснение]  
Кому адресован: [группа участников]
"""

llm = HuggingFaceEndpoint(
    repo_id="google/gemma-2-27b",
    task="text-generation",
)

def get_context(text):
    try:
        chat = ChatHuggingFace(llm=llm, verbose=True)
        messages = [
            ("system", prompt),
            ("human", text),
        ] 

        ai_msg = chat.invoke(messages)
        return ai_msg.choices[0].message.content
    except Exception as e:
        print(e)
        return None
